{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5377440,"sourceType":"datasetVersion","datasetId":3119215}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aashutoshh01/face-detection?scriptVersionId=191269804\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Face Detection Model**","metadata":{}},{"cell_type":"markdown","source":"* **Aashutosh Joshi**\n* **Indian Institute of Technology, Kharagpur**","metadata":{}},{"cell_type":"markdown","source":"# **Import Module**","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport shutil\nimport cv2\nimport random\nimport matplotlib.pyplot as plt\nimport copy\nimport wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-05T10:33:38.139207Z","iopub.execute_input":"2024-08-05T10:33:38.140046Z","iopub.status.idle":"2024-08-05T10:33:40.27831Z","shell.execute_reply.started":"2024-08-05T10:33:38.140011Z","shell.execute_reply":"2024-08-05T10:33:40.277261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Working With Directory**","metadata":{}},{"cell_type":"markdown","source":"By structuring the file paths in the following way, we code can dynamically adapt to different working directories and ensures that paths to data directories are consistently and correctly formed.\n* **curr_path** holds the current working directory path.\n* **imgtrainpath**, **imgvalpath**, and **imgtestpath** are paths to the directories where training, validation, and testing images are stored, respectively.\n* **labeltrainpath**, **labelvalpath**, and **labeltestpath** are paths to the directories where training, validation, and testing labels are stored, respectively.\n","metadata":{}},{"cell_type":"code","source":"curr_path=os.getcwd()\nimgtrainpath = os.path.join(curr_path,'images','train')\nimgvalpath=os.path.join(curr_path,'images','validation')\nimgtestpath=os.path.join(curr_path,'images','test')\n\nlabeltrainpath=os.path.join(curr_path,'labels','train')\nlabelvalpath=os.path.join(curr_path,'labels','validation')\nlabeltestpath=os.path.join(curr_path,'labels','test')","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.280216Z","iopub.execute_input":"2024-08-05T10:33:40.280524Z","iopub.status.idle":"2024-08-05T10:33:40.287685Z","shell.execute_reply.started":"2024-08-05T10:33:40.280496Z","shell.execute_reply":"2024-08-05T10:33:40.28642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bs=' ' # blank-space\nclass_id=0 # id for face\nnewline='\\n' # new line character\nextension='.txt' # extension for text file","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.290863Z","iopub.execute_input":"2024-08-05T10:33:40.291132Z","iopub.status.idle":"2024-08-05T10:33:40.297472Z","shell.execute_reply.started":"2024-08-05T10:33:40.291108Z","shell.execute_reply":"2024-08-05T10:33:40.296409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By defining the following paths below,we can easily refer to our data and labels throughout our code without hardcoding the directory structure multiple times.","metadata":{}},{"cell_type":"code","source":"data_path='/kaggle/input/human-faces-object-detection'\nlabels_path = os.path.join(curr_path, 'face_labels')","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.300297Z","iopub.execute_input":"2024-08-05T10:33:40.300647Z","iopub.status.idle":"2024-08-05T10:33:40.3062Z","shell.execute_reply.started":"2024-08-05T10:33:40.300613Z","shell.execute_reply":"2024-08-05T10:33:40.305121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By running the following line of code, we ensure that the directory for storing face label files exists, which is useful for organizing our data and labels in a consistent directory structure.","metadata":{}},{"cell_type":"code","source":"os.makedirs(labels_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.30781Z","iopub.execute_input":"2024-08-05T10:33:40.308365Z","iopub.status.idle":"2024-08-05T10:33:40.313879Z","shell.execute_reply.started":"2024-08-05T10:33:40.308332Z","shell.execute_reply":"2024-08-05T10:33:40.312969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following function is useful for inspecting the contents of a directory, allowing us to programmatically access and manipulate the files and subdirectories within it.","metadata":{}},{"cell_type":"code","source":"os.listdir(data_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.315408Z","iopub.execute_input":"2024-08-05T10:33:40.315749Z","iopub.status.idle":"2024-08-05T10:33:40.327222Z","shell.execute_reply.started":"2024-08-05T10:33:40.315719Z","shell.execute_reply":"2024-08-05T10:33:40.326216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By defining the following paths in the cell below, we can easily access and manipulate the images and annotations in our dataset without hardcoding the directory structure multiple times, ensuring our code remains flexible and maintainable.\n* **img_path** is constructed to hold the path to the '**images**' subdirectory within our dataset directory, which is where our image files are stored.\n* **raw_annotations_path** is constructed to hold the path to the '**faces.csv**' file within our dataset directory, which is where our raw annotations or metadata are stored.","metadata":{}},{"cell_type":"code","source":"img_path=os.path.join(data_path, 'images')\nraw_annotations_path=os.path.join(data_path, 'faces.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.328476Z","iopub.execute_input":"2024-08-05T10:33:40.329313Z","iopub.status.idle":"2024-08-05T10:33:40.334092Z","shell.execute_reply.started":"2024-08-05T10:33:40.329281Z","shell.execute_reply":"2024-08-05T10:33:40.333127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following cell is useful for\n* Iterating over the images in the directory.\n* Processing each image file, such as loading the images into memory, performing operations on them, or using them for training a model.","metadata":{}},{"cell_type":"code","source":"face_list=os.listdir(img_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.335418Z","iopub.execute_input":"2024-08-05T10:33:40.335746Z","iopub.status.idle":"2024-08-05T10:33:40.470607Z","shell.execute_reply.started":"2024-08-05T10:33:40.33572Z","shell.execute_reply":"2024-08-05T10:33:40.469465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face_list[:5]","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.472018Z","iopub.execute_input":"2024-08-05T10:33:40.472688Z","iopub.status.idle":"2024-08-05T10:33:40.479577Z","shell.execute_reply.started":"2024-08-05T10:33:40.472652Z","shell.execute_reply":"2024-08-05T10:33:40.478499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_len=len(face_list)\ndata_len","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.483707Z","iopub.execute_input":"2024-08-05T10:33:40.483987Z","iopub.status.idle":"2024-08-05T10:33:40.493425Z","shell.execute_reply.started":"2024-08-05T10:33:40.483964Z","shell.execute_reply":"2024-08-05T10:33:40.492506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.shuffle(face_list)\nface_list[:5]","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.494823Z","iopub.execute_input":"2024-08-05T10:33:40.495108Z","iopub.status.idle":"2024-08-05T10:33:40.504308Z","shell.execute_reply.started":"2024-08-05T10:33:40.495083Z","shell.execute_reply":"2024-08-05T10:33:40.503342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Train Test Split**","metadata":{}},{"cell_type":"code","source":"train_split=0.8\nval_split=0.1\ntest_split=0.1\n\nimgtrain_list=face_list[:int(data_len*train_split)]\nimgval_list=face_list[int(data_len*train_split):int(data_len*(train_split+val_split))]\nimgtest_list=face_list[int(data_len*(train_split+val_split)):]","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.50599Z","iopub.execute_input":"2024-08-05T10:33:40.506429Z","iopub.status.idle":"2024-08-05T10:33:40.512011Z","shell.execute_reply.started":"2024-08-05T10:33:40.506406Z","shell.execute_reply":"2024-08-05T10:33:40.511039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgtest_list[:5]","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.513455Z","iopub.execute_input":"2024-08-05T10:33:40.513795Z","iopub.status.idle":"2024-08-05T10:33:40.521205Z","shell.execute_reply.started":"2024-08-05T10:33:40.513764Z","shell.execute_reply":"2024-08-05T10:33:40.520197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(imgtrain_list), len(imgval_list), len(imgtest_list)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.522072Z","iopub.execute_input":"2024-08-05T10:33:40.522404Z","iopub.status.idle":"2024-08-05T10:33:40.53107Z","shell.execute_reply.started":"2024-08-05T10:33:40.52238Z","shell.execute_reply":"2024-08-05T10:33:40.530191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This function below is useful for changing the file extension of filenames while keeping the base name intact, such as when converting files from one format to another.\n* **change_extension(file)**: Takes a file path as input, removes its current extension, and replaces it with a new extension defined by the **extension** variable.\n* For instance, if you call **change_extension('image.jpg')** and extension is '**.png**', the function will return '**image.png**'.","metadata":{}},{"cell_type":"code","source":"def change_extension(file):\n    basename=os.path.splitext(file)[0]\n    filename=basename+extension\n    return filename","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.532017Z","iopub.execute_input":"2024-08-05T10:33:40.53235Z","iopub.status.idle":"2024-08-05T10:33:40.538119Z","shell.execute_reply.started":"2024-08-05T10:33:40.532315Z","shell.execute_reply":"2024-08-05T10:33:40.536984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The approach in the cell below is useful for creating corresponding label files or other related files that follow a different naming convention or file format.\n* **labeltrain_list**: A list of filenames for the training set with the new file extension.\n* **labelval_list**: A list of filenames for the validation set with the new file extension.\n* **labeltest_list**: A list of filenames for the testing set with the new file extension.","metadata":{}},{"cell_type":"code","source":"labeltrain_list = list(map(change_extension, imgtrain_list)) \nlabelval_list = list(map(change_extension, imgval_list)) \nlabeltest_list = list(map(change_extension, imgtest_list)) ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.539441Z","iopub.execute_input":"2024-08-05T10:33:40.539733Z","iopub.status.idle":"2024-08-05T10:33:40.550853Z","shell.execute_reply.started":"2024-08-05T10:33:40.53971Z","shell.execute_reply":"2024-08-05T10:33:40.549969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(labeltrain_list), len(labelval_list), len(labeltest_list)\nlabeltest_list[:5] ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.551926Z","iopub.execute_input":"2024-08-05T10:33:40.552207Z","iopub.status.idle":"2024-08-05T10:33:40.560588Z","shell.execute_reply.started":"2024-08-05T10:33:40.552181Z","shell.execute_reply":"2024-08-05T10:33:40.559649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Reading a CSV file into the DataFrame**","metadata":{}},{"cell_type":"markdown","source":"In the cell below\n* **pd.read_csv(raw_annotations_path)**: Reads the CSV file specified by **raw_annotations_path** and creates a DataFrame from it.\n* **raw_annotations**: Holds the DataFrame with the contents of the CSV file, allowing for further manipulation and analysis.","metadata":{}},{"cell_type":"code","source":"raw_annotations=pd.read_csv(raw_annotations_path)\nraw_annotations","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.56177Z","iopub.execute_input":"2024-08-05T10:33:40.56206Z","iopub.status.idle":"2024-08-05T10:33:40.598299Z","shell.execute_reply.started":"2024-08-05T10:33:40.562036Z","shell.execute_reply":"2024-08-05T10:33:40.597206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The new columns in the following cell are useful for tasks like training object detection models, where bounding box center coordinates and dimensions are often required.\n* **raw_annotations['x_centre']**: Contains the center x-coordinate of the bounding boxes.\n* **raw_annotations['y_centre']**: Contains the center y-coordinate of the bounding boxes.\n* **raw_annotations['bb_width']**: Contains the width of the bounding boxes.\n* **raw_annotations['bb_height']**: Contains the height of the bounding boxes.","metadata":{}},{"cell_type":"code","source":"raw_annotations['x_centre']=0.5*(raw_annotations['x0']+raw_annotations['x1'])\nraw_annotations['y_centre']=0.5*(raw_annotations['y0']+raw_annotations['y1'])\nraw_annotations['bb_width']=raw_annotations['x1']-raw_annotations['x0']\nraw_annotations['bb_height']=raw_annotations['y1']-raw_annotations['y0']\nraw_annotations","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.599499Z","iopub.execute_input":"2024-08-05T10:33:40.599849Z","iopub.status.idle":"2024-08-05T10:33:40.628978Z","shell.execute_reply.started":"2024-08-05T10:33:40.599795Z","shell.execute_reply":"2024-08-05T10:33:40.627959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Normalizing the bounding box coordinates and dimensions to be between 0 and 1 is a common preprocessing step in many computer vision tasks, particularly for object detection models. It helps standardize the data and ensures that the bounding box values are relative to the size of the image, which can improve the model's performance and consistency.\n\nIn the cell below:\n* **raw_annotations['xcentre_scaled']**: Contains the normalized center x-coordinate of the bounding boxes, scaled relative to the width of the image.\n* **raw_annotations['ycentre_scaled']**: Contains the normalized center y-coordinate of the bounding boxes, scaled relative to the height of the image.\n* **raw_annotations['width_scaled']**: Contains the normalized width of the bounding boxes, scaled relative to the width of the image.\n* **raw_annotations['height_scaled']**: Contains the normalized height of the bounding boxes, scaled relative to the height of the image.","metadata":{}},{"cell_type":"code","source":"raw_annotations['xcentre_scaled']=raw_annotations['x_centre']/raw_annotations['width']\nraw_annotations['ycentre_scaled']=raw_annotations['y_centre']/raw_annotations['height']\nraw_annotations['width_scaled']=raw_annotations['bb_width']/raw_annotations['width']\nraw_annotations['height_scaled']=raw_annotations['bb_height']/raw_annotations['height']\nraw_annotations","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.63022Z","iopub.execute_input":"2024-08-05T10:33:40.630588Z","iopub.status.idle":"2024-08-05T10:33:40.659655Z","shell.execute_reply.started":"2024-08-05T10:33:40.630554Z","shell.execute_reply":"2024-08-05T10:33:40.658628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(raw_annotations['image_name'].unique())","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.660868Z","iopub.execute_input":"2024-08-05T10:33:40.661259Z","iopub.status.idle":"2024-08-05T10:33:40.670837Z","shell.execute_reply.started":"2024-08-05T10:33:40.661223Z","shell.execute_reply":"2024-08-05T10:33:40.669583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Preprocessing**","metadata":{}},{"cell_type":"markdown","source":"In the cell below:\n* **imgs**: Holds a **GroupBy** object created by grouping **raw_annotations** by the **image_name** column.\n* This allows you to perform operations on subsets of data that share the same **image_name**, making it easier to analyze and process data associated with each image.","metadata":{}},{"cell_type":"code","source":"imgs=raw_annotations.groupby('image_name') ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.672641Z","iopub.execute_input":"2024-08-05T10:33:40.673003Z","iopub.status.idle":"2024-08-05T10:33:40.68113Z","shell.execute_reply.started":"2024-08-05T10:33:40.672969Z","shell.execute_reply":"2024-08-05T10:33:40.680024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the cell below:\n* **Purpose**: The code processes bounding box annotations for each image and writes them into a text file where each line represents an object annotation in the format required.\n* **File Creation**: For each image, it generates a label file with annotations, with each annotation line containing normalized coordinates and dimensions.","metadata":{}},{"cell_type":"code","source":"#Loop Through Groups:\nfor image in imgs:\n    \n    #Get DataFrame for Each Image:\n    img_df=imgs.get_group(image[0])\n    \n    #Generate Filename for the Label File:\n    basename=os.path.splitext(image[0])[0]\n    txt_file=basename+extension\n    filepath=os.path.join(labels_path, txt_file)\n    \n    #Prepare Lines for the Label File:\n    lines=[]\n    i=1\n    \n    #Generate Annotation Lines:\n    for index,row in img_df.iterrows():\n        \n        #Check if the current row is not the last one\n        if i!=len(img_df):\n            line=str(class_id)+bs+str(row['xcentre_scaled'])+bs+str(row['ycentre_scaled'])+bs+str(row['width_scaled'])+bs+str(row['height_scaled'])+newline\n            lines.append(line)\n        else:\n            line=str(class_id)+bs+str(row['xcentre_scaled'])+bs+str(row['ycentre_scaled'])+bs+str(row['width_scaled'])+bs+ str(row['height_scaled'])\n            lines.append(line)\n        i=i+1\n    \n    #Write to the Label File:\n    with open(filepath, 'w') as file:\n        file.writelines(lines)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:40.682466Z","iopub.execute_input":"2024-08-05T10:33:40.682868Z","iopub.status.idle":"2024-08-05T10:33:42.81066Z","shell.execute_reply.started":"2024-08-05T10:33:40.68283Z","shell.execute_reply":"2024-08-05T10:33:42.809294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Following snippet is useful for verifying the contents of a randomly chosen label file to ensure that the annotation data is formatted correctly and has been written as expected.\n* **os.listdir(labels_path)[:5]**: Lists the first 5 files or directories in the labels_path directory.\n* **random_file**: Constructs the path to the 5th file in the directory\n* **Reading File**: Opens and reads the content of the selected label file into the content variable.\n* **content**: Contains the data from the label file, which is printed or displayed.","metadata":{}},{"cell_type":"code","source":"#List Files in Directory (os.listdir):\nos.listdir(labels_path)[:5]\n\n#Select a Random File (random_file):\nrandom_file=os.path.join(labels_path, os.listdir(labels_path)[4])\n\n#Read the Content of the Selected File:\nwith open (random_file, 'r') as f:\n    content=f.read()\n    \n#Display Content:\ncontent","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:42.812562Z","iopub.execute_input":"2024-08-05T10:33:42.81377Z","iopub.status.idle":"2024-08-05T10:33:42.826897Z","shell.execute_reply.started":"2024-08-05T10:33:42.813726Z","shell.execute_reply":"2024-08-05T10:33:42.825758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def_size=640\nlen(os.listdir(labels_path)) ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:42.828385Z","iopub.execute_input":"2024-08-05T10:33:42.828739Z","iopub.status.idle":"2024-08-05T10:33:42.837756Z","shell.execute_reply.started":"2024-08-05T10:33:42.828711Z","shell.execute_reply":"2024-08-05T10:33:42.836446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the following cell:\n* **Purpose**: The **move_files** function moves files from a specified source directory to a destination directory.\n* **File Path Construction**: Constructs full file paths for both source and destination.\n* **Directory Creation**: Creates the destination directory if it does not already exist.\n* **File Movement**: Moves each file and counts the number of files moved.\n* **Completion Message**: Prints the total number of files transferred.","metadata":{}},{"cell_type":"code","source":"def move_files(data_list, source_path, destination_path):\n    \n    #Initialize Counter:\n    i=0\n    \n    #Loop Through Files:\n    for file in data_list:\n        \n        #Construct File Paths:\n        filepath=os.path.join(source_path, file)\n        dest_path=os.path.join(data_path, destination_path)\n        \n        #Create Destination Directory if Needed:\n        if not os.path.isdir(dest_path):\n            os.makedirs(dest_path)\n            \n        #Move File:\n        shutil.move(filepath, dest_path)\n        \n        #Update Counter:\n        i=i+1\n    print(\"Number of files transferred:\", i)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:42.839304Z","iopub.execute_input":"2024-08-05T10:33:42.839618Z","iopub.status.idle":"2024-08-05T10:33:42.847637Z","shell.execute_reply.started":"2024-08-05T10:33:42.839592Z","shell.execute_reply":"2024-08-05T10:33:42.846227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Following move_images function is designed to move and resize images from a source directory to a destination directory.\n* **Purpose**: The **move_images** function resizes images from a source directory and moves them to a destination directory.\n* **Image Processing**: Uses OpenCV to read, resize, and save images.\n* **Directory Handling**: Ensures the destination directory exists and creates it if necessary.\n* **Tracking**: Counts the number of processed images and prints this count at the end.","metadata":{}},{"cell_type":"code","source":"def move_images(data_list, source_path, destination_path):\n    \n    #Initialize Counter:\n    i=0\n    \n    #Loop Through Files:\n    for file in data_list:\n        \n        #Construct File Paths:\n        filepath=os.path.join(source_path, file)\n        dest_path=os.path.join(data_path, destination_path)\n        \n        #Create Destination Directory if Needed:\n        if not os.path.isdir(dest_path):\n            os.makedirs(dest_path)\n            \n        #Resize and Save Image:\n        finalimage_path=os.path.join(dest_path, file)\n        img_resized=cv2.resize(cv2.imread(filepath), (def_size, def_size))\n        cv2.imwrite(finalimage_path, img_resized)\n        \n        #Update Counter:\n        i=i+1\n    print(\"Number of files transferred:\", i)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:42.849089Z","iopub.execute_input":"2024-08-05T10:33:42.849573Z","iopub.status.idle":"2024-08-05T10:33:42.858748Z","shell.execute_reply.started":"2024-08-05T10:33:42.849536Z","shell.execute_reply":"2024-08-05T10:33:42.857606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The step in the cell below is crucial for preparing the dataset for machine learning or computer vision tasks, ensuring that all training images are uniformly resized and organized.\n* **Purpose**: This line of code initiates the process of resizing and moving training images from their original location to a designated training directory.\n* **Data Handling**: Ensures that images are properly resized and stored in the correct location for training purposes.\n* **Function Integration**: Utilizes the **move_images** function to automate and streamline the process of preparing training data.","metadata":{}},{"cell_type":"code","source":"move_images(imgtrain_list, img_path, imgtrainpath)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:33:42.868865Z","iopub.execute_input":"2024-08-05T10:33:42.869386Z","iopub.status.idle":"2024-08-05T10:34:12.171658Z","shell.execute_reply.started":"2024-08-05T10:33:42.86935Z","shell.execute_reply":"2024-08-05T10:34:12.170704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"move_images(imgval_list, img_path, imgvalpath)\nmove_images(imgtest_list, img_path, imgtestpath)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:34:12.173135Z","iopub.execute_input":"2024-08-05T10:34:12.173521Z","iopub.status.idle":"2024-08-05T10:34:20.383324Z","shell.execute_reply.started":"2024-08-05T10:34:12.173488Z","shell.execute_reply":"2024-08-05T10:34:20.382294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"move_files(labeltrain_list, labels_path, labeltrainpath)\nmove_files(labelval_list, labels_path, labelvalpath)\nmove_files(labeltest_list, labels_path, labeltestpath)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:34:20.384738Z","iopub.execute_input":"2024-08-05T10:34:20.385536Z","iopub.status.idle":"2024-08-05T10:34:20.523887Z","shell.execute_reply.started":"2024-08-05T10:34:20.385499Z","shell.execute_reply":"2024-08-05T10:34:20.52293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the following cell:\n* **Counting Files**: The **len(os.listdir(labels_path))** part of the code calculates how many items are in the **labels_path** directory.\n* **Deleting Directory**: The **shutil.rmtree(labels_path)** part of the code removes the **labels_path** directory and all its contents, effectively cleaning up or resetting the directory state.","metadata":{}},{"cell_type":"code","source":"len(os.listdir(labels_path)) \nshutil.rmtree(labels_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:34:20.52505Z","iopub.execute_input":"2024-08-05T10:34:20.525375Z","iopub.status.idle":"2024-08-05T10:34:20.530222Z","shell.execute_reply.started":"2024-08-05T10:34:20.525349Z","shell.execute_reply":"2024-08-05T10:34:20.529179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The configuration file in the cell below is typically used by machine learning frameworks to load datasets and understand the structure and classes of the data.\n\nThe config_lines list contains all the necessary lines to create a configuration file with:\n* Paths to training, validation, and test datasets.\n* Class definitions for object detection or classification tasks.","metadata":{}},{"cell_type":"code","source":"ln_1='# Train/val/test sets'+newline\nln_2='train: ' +\"'\"+imgtrainpath+\"'\"+newline\nln_3='val: ' +\"'\" + imgvalpath+\"'\"+newline\nln_4='test: ' +\"'\" + imgtestpath+\"'\"+newline\nln_5=newline\nln_6='# Classes'+newline\nln_7='names:'+newline\nln_8='  0: face'\nconfig_lines=[ln_1, ln_2, ln_3, ln_4, ln_5, ln_6, ln_7, ln_8]","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:34:20.531516Z","iopub.execute_input":"2024-08-05T10:34:20.532244Z","iopub.status.idle":"2024-08-05T10:34:20.539132Z","shell.execute_reply.started":"2024-08-05T10:34:20.532193Z","shell.execute_reply":"2024-08-05T10:34:20.537752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the following cell:\n* **config_path**: This variable holds the full path to the **config.yaml** file in the current working directory.\n* **Purpose**: Used to specify where the configuration file is located for writing or reading configuration settings.","metadata":{}},{"cell_type":"code","source":"config_path=os.path.join(curr_path, 'config.yaml')\nconfig_path","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:34:20.54034Z","iopub.execute_input":"2024-08-05T10:34:20.540623Z","iopub.status.idle":"2024-08-05T10:34:20.550092Z","shell.execute_reply.started":"2024-08-05T10:34:20.5406Z","shell.execute_reply":"2024-08-05T10:34:20.549086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the cell below:\n* **Purpose**: The code writes the configuration settings to a file named **config.yaml**.\n* **File Handling**: Opens the file in write mode and ensures it is closed properly after writing.\n* **Writing Lines**: Uses the writelines method to write a list of lines to the file.","metadata":{}},{"cell_type":"code","source":"with open(config_path, 'w') as f:\n    f.writelines(config_lines)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:34:20.551753Z","iopub.execute_input":"2024-08-05T10:34:20.552117Z","iopub.status.idle":"2024-08-05T10:34:20.557439Z","shell.execute_reply.started":"2024-08-05T10:34:20.552086Z","shell.execute_reply":"2024-08-05T10:34:20.556604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Image Visualization**","metadata":{}},{"cell_type":"markdown","source":"The **get_bbox_from_label** function below:\n\n* Reads a text file containing bounding box data.\n* Parses the data to extract bounding box coordinates.\n* Converts the coordinates from normalized values to pixel values.\n* Constructs a list of bounding box vertices.\n* Returns the list as a tuple.","metadata":{}},{"cell_type":"code","source":"#Function Definition and Initialization\ndef get_bbox_from_label(text_file_path):\n    \n    #Opening and Reading the File\n    bbox_list=[]\n    with open(text_file_path, \"r\") as file:\n        for line in file:\n            \n            #Processing Each Line\n            _,x_centre,y_centre,width,height=line.strip().split(\" \")\n            x1=(float(x_centre)+(float(width)/2))*def_size\n            x0=(float(x_centre)-(float(width)/2))*def_size\n            y1=(float(y_centre)+(float(height)/2))*def_size\n            y0=(float(y_centre)-(float(height)/2))*def_size\n            \n            #Creating Vertices and Appending to List\n            vertices=np.array([[int(x0), int(y0)], [int(x1), int(y0)], \n                               [int(x1),int(y1)], [int(x0),int(y1)]])\n            bbox_list.append(vertices)      \n     \n    #Return the Bounding Boxes\n    return tuple(bbox_list)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:34:20.558517Z","iopub.execute_input":"2024-08-05T10:34:20.558848Z","iopub.status.idle":"2024-08-05T10:34:20.56809Z","shell.execute_reply.started":"2024-08-05T10:34:20.558824Z","shell.execute_reply":"2024-08-05T10:34:20.566965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"red=(255,0,0) ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:34:20.569369Z","iopub.execute_input":"2024-08-05T10:34:20.570005Z","iopub.status.idle":"2024-08-05T10:34:20.575709Z","shell.execute_reply.started":"2024-08-05T10:34:20.569974Z","shell.execute_reply":"2024-08-05T10:34:20.574712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the cell below:\n\n**Figure Setup**: Initializes a large figure with dimensions 30x30 inches.\n\n**Loop**: Iterates through a specified range to create pairs of subplots.\n* Randomly selects an image and its corresponding label.\n* Reads the image and creates a deep copy.\n* Extracts bounding box coordinates from the label.\n* Displays the original image in one subplot.\n* Draws bounding boxes on the copied image and displays it in the adjacent subplot.","metadata":{}},{"cell_type":"code","source":"#Set Up the Figure\nplt.figure(figsize=(30,30))\n\n#Loop to Process and Display Images\nfor i in range(1,8,2):\n    \n    #Random Selection:\n    k=random.randint(0, len(imgtrain_list)-1)\n    \n    #Paths for Image and Label:\n    img_path=os.path.join(imgtrainpath, imgtrain_list[k])\n    label_path=os.path.join(labeltrainpath, labeltrain_list[k])\n    \n    #Bounding Box Extraction:\n    bbox=get_bbox_from_label(label_path)\n    \n    #Image Reading and Copy:\n    image=cv2.imread(img_path)\n    image_copy=copy.deepcopy(image)\n    \n    #Display Original Image\n    ax=plt.subplot(4, 2, i)\n    plt.imshow(image) \n    plt.xticks([])\n    plt.yticks([])\n    \n    #Draw Bounding Box and Display Annotated Image\n    cv2.drawContours(image_copy, bbox, -1, red, 2) \n    ax=plt.subplot(4, 2, i+1)\n    plt.imshow(image_copy) \n    plt.xticks([])\n    plt.yticks([])","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:34:20.577Z","iopub.execute_input":"2024-08-05T10:34:20.577335Z","iopub.status.idle":"2024-08-05T10:34:22.597761Z","shell.execute_reply.started":"2024-08-05T10:34:20.57731Z","shell.execute_reply":"2024-08-05T10:34:22.596632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Importing Model**","metadata":{}},{"cell_type":"markdown","source":"**ultralytics** is the name of the package we want to install. Ultralytics is known for developing YOLO (You Only Look Once) models for object detection.","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:34:22.599057Z","iopub.execute_input":"2024-08-05T10:34:22.599396Z","iopub.status.idle":"2024-08-05T10:34:38.202863Z","shell.execute_reply.started":"2024-08-05T10:34:22.599368Z","shell.execute_reply":"2024-08-05T10:34:38.20168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cell below imports the **YOLO** class from the **ultralytics** package","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:34:38.204417Z","iopub.execute_input":"2024-08-05T10:34:38.204766Z","iopub.status.idle":"2024-08-05T10:34:41.683714Z","shell.execute_reply.started":"2024-08-05T10:34:38.204731Z","shell.execute_reply":"2024-08-05T10:34:41.682865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet below initializes a **YOLOv8** model using a configuration file ('**yolov8n.yaml**') and loads pre-trained weights ('**yolov8n.pt**'). This setup allows us to perform object detection tasks with the pre-trained YOLOv8 model.","metadata":{}},{"cell_type":"code","source":"model=YOLO('yolov8n.yaml').load('yolov8n.pt')","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:34:41.684969Z","iopub.execute_input":"2024-08-05T10:34:41.685474Z","iopub.status.idle":"2024-08-05T10:34:42.659926Z","shell.execute_reply.started":"2024-08-05T10:34:41.685445Z","shell.execute_reply":"2024-08-05T10:34:42.659006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training The YOLO Model**","metadata":{}},{"cell_type":"markdown","source":"Following cell initiates the training process of the YOLO model with specific parameters. Here's a detailed explanation of each part:\n\n**Breakdown of Code**\n\n**model.train()**\n* **train()**: This is a method of the YOLO class that starts the training process for the model.\n**Parameters:**\n* **data=config_path**: **data** specifies the path to the data configuration file, which contains information about the dataset, including paths to training, validation, and test sets, as well as class names. Here, **config_path** is the variable holding the path to your configuration file ('**config.yaml**').\n* **epochs=100**: **epochs** specifies the number of training epochs. An epoch is one complete pass through the entire training dataset. Here, the model will train for 100 epochs.\n* **resume=True**: **resume** indicates whether to resume training from the last checkpoint. If set to **True**, training will continue from where it left off, using saved checkpoints.\n* **iou=0.5**: **iou** is Intersection over Union threshold for evaluation. It is used to determine whether a predicted bounding box is considered a true positive. A higher IoU threshold means stricter evaluation criteria.\n* **conf=0.001**: **conf** is confidence threshold for object detection. It sets the minimum confidence level required for a prediction to be considered valid. Lower values allow more detections but can increase false positives.","metadata":{}},{"cell_type":"code","source":"results=model.train(data=config_path, epochs=100, resume=True, iou=0.5, conf=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T10:34:42.661335Z","iopub.execute_input":"2024-08-05T10:34:42.661654Z","iopub.status.idle":"2024-08-05T11:11:43.988905Z","shell.execute_reply.started":"2024-08-05T10:34:42.661626Z","shell.execute_reply":"2024-08-05T11:11:43.987831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Evaluation And Plots**","metadata":{}},{"cell_type":"markdown","source":"Code snippet below is used to visualize the training results of the **YOLO** model by displaying an image file named results.png, which typically contains training metrics such as loss and accuracy curves. ","metadata":{}},{"cell_type":"code","source":"#Create a large figure for plotting\nplt.figure(figsize=(30,30))\n\n#Construct the path to the training results\ntrainingresult_path=os.path.join(curr_path, 'runs', 'detect', 'train')\n\n#Read the results image\nresults_png=cv2.imread(os.path.join(trainingresult_path,'results.png'))\n\n#Display the results image\nplt.imshow(results_png)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T11:11:43.990455Z","iopub.execute_input":"2024-08-05T11:11:43.990789Z","iopub.status.idle":"2024-08-05T11:11:45.488127Z","shell.execute_reply.started":"2024-08-05T11:11:43.990755Z","shell.execute_reply":"2024-08-05T11:11:45.487089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The function **evaluate_map50** is designed to evaluate a trained **YOLO** model on a specified dataset and calculate the **mean Average Precision (mAP)** at an **IoU** threshold of **0.5**.","metadata":{}},{"cell_type":"code","source":"#Function Definition\ndef evaluate_map50(trainedmodel, data_path, dataset='val'):\n    \n    #Evaluate the Model\n    metrics=trainedmodel.val(data=data_path, split=dataset)\n    \n    #Calculate mAP@50\n    map50=round(metrics.box.map50, 3)\n    \n    #Print the Results\n    print(\"The mAP of model on {0} dataset is {1}\".format(dataset,map50))\n    \n    #Return the Results\n    return metrics, map50","metadata":{"execution":{"iopub.status.busy":"2024-08-05T11:11:45.489535Z","iopub.execute_input":"2024-08-05T11:11:45.489851Z","iopub.status.idle":"2024-08-05T11:11:45.495503Z","shell.execute_reply.started":"2024-08-05T11:11:45.489825Z","shell.execute_reply":"2024-08-05T11:11:45.494559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The **display_curves** function is designed to display various plots generated during the training and evaluation of a **YOLO** model. The plots include the **Precision curve**, **Recall curve**, **Precision-Recall curve**, **F1 curve**, and the **Confusion matrix**. These plots provide insights into the model's performance and behavior.","metadata":{}},{"cell_type":"code","source":"#Function Definition\ndef display_curves(root_path):\n    \n    #Create a Figure\n    plt.figure(figsize=(50,50))\n    \n    #Display the Precision Curve\n    p_curve=cv2.imread(os.path.join(root_path,\"P_curve.png\"))\n    ax=plt.subplot(5,1,1)\n    print(p_curve)\n    plt.imshow(p_curve)\n    \n    #Display the Recall Curve\n    r_curve=cv2.imread(os.path.join(root_path,\"R_curve.png\"))\n    ax=plt.subplot(5,1,2)\n    plt.imshow(r_curve)\n    \n    #Display the Precision-Recall Curve\n    pr_curve=cv2.imread(os.path.join(root_path,\"PR_curve.png\"))\n    ax=plt.subplot(5,1,3)\n    plt.imshow(pr_curve)\n    \n    #Display the F1 Curve\n    f1_curve=cv2.imread(os.path.join(root_path,\"F1_curve.png\"))\n    ax=plt.subplot(5,1,4)\n    plt.imshow(f1_curve)\n    \n    #Display the Confusion Matrix\n    confusion_matrix=cv2.imread(os.path.join(root_path,\"confusion_matrix.png\"))\n    ax=plt.subplot(5,1,5)\n    plt.imshow(confusion_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T11:11:45.496778Z","iopub.execute_input":"2024-08-05T11:11:45.497084Z","iopub.status.idle":"2024-08-05T11:11:45.506621Z","shell.execute_reply.started":"2024-08-05T11:11:45.497034Z","shell.execute_reply":"2024-08-05T11:11:45.505632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Following line of code allows us to assess the performance of our **YOLO** model on the training dataset, providing insight into how well the model has learned to detect objects during the training phase.","metadata":{}},{"cell_type":"code","source":"train_metrics, train_map50=evaluate_map50(model, config_path, dataset='train')","metadata":{"execution":{"iopub.status.busy":"2024-08-05T11:11:45.508001Z","iopub.execute_input":"2024-08-05T11:11:45.508561Z","iopub.status.idle":"2024-08-05T11:12:06.609993Z","shell.execute_reply.started":"2024-08-05T11:11:45.508525Z","shell.execute_reply":"2024-08-05T11:12:06.608943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the cell below the variable **train_path** is set to a directory that contains the evaluation results for a specific training run (**'train2'**). This directory is used to store results from evaluating the model on the training dataset, not on a validation dataset. The path is constructed using **os.path.join** to ensure it correctly points to the location within the file system based on the current working directory.","metadata":{}},{"cell_type":"code","source":"train_path=os.path.join(curr_path, 'runs', 'detect', 'train2') #val is a misnomer, it is actually measuring validation on training dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-05T11:12:06.612649Z","iopub.execute_input":"2024-08-05T11:12:06.613731Z","iopub.status.idle":"2024-08-05T11:12:06.61918Z","shell.execute_reply.started":"2024-08-05T11:12:06.613687Z","shell.execute_reply":"2024-08-05T11:12:06.618108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the cell below visualization helps in assessing the performance of the model on the training dataset by providing a clear view of various metrics, allowing us to analyze and interpret the results of our model training and evaluation.","metadata":{}},{"cell_type":"code","source":"display_curves(train_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T11:12:06.620548Z","iopub.execute_input":"2024-08-05T11:12:06.620875Z","iopub.status.idle":"2024-08-05T11:12:12.432933Z","shell.execute_reply.started":"2024-08-05T11:12:06.620848Z","shell.execute_reply":"2024-08-05T11:12:12.431977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Line of code in the cell below helps us to assess how well the **YOLO** model performs on the validation dataset, providing important insights into its ability to detect objects accurately when exposed to unseen data.","metadata":{}},{"cell_type":"code","source":"val_metrics, val_map50=evaluate_map50(model, config_path, dataset='val')","metadata":{"execution":{"iopub.status.busy":"2024-08-05T11:12:12.434449Z","iopub.execute_input":"2024-08-05T11:12:12.435114Z","iopub.status.idle":"2024-08-05T11:12:20.961739Z","shell.execute_reply.started":"2024-08-05T11:12:12.435077Z","shell.execute_reply":"2024-08-05T11:12:20.960398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cell below is used to define the path to a specific directory where evaluation results or training outputs are stored.","metadata":{}},{"cell_type":"code","source":"val_path=os.path.join(curr_path, 'runs', 'detect', 'train4') ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T11:12:20.96444Z","iopub.execute_input":"2024-08-05T11:12:20.965465Z","iopub.status.idle":"2024-08-05T11:12:20.971844Z","shell.execute_reply.started":"2024-08-05T11:12:20.965411Z","shell.execute_reply":"2024-08-05T11:12:20.970637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cell below is used to evaluate the performance of a trained **YOLO** model on the test dataset.","metadata":{}},{"cell_type":"code","source":"test_metrics, test_map50=evaluate_map50(model, config_path, dataset='test')","metadata":{"execution":{"iopub.status.busy":"2024-08-05T11:12:20.974008Z","iopub.execute_input":"2024-08-05T11:12:20.974909Z","iopub.status.idle":"2024-08-05T11:12:29.533229Z","shell.execute_reply.started":"2024-08-05T11:12:20.974875Z","shell.execute_reply":"2024-08-05T11:12:29.532034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cell below is used to define the path to a directory where evaluation results for a specific training run are stored.","metadata":{}},{"cell_type":"code","source":"test_path=os.path.join(curr_path, 'runs', 'detect', 'train3') ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T11:12:29.535586Z","iopub.execute_input":"2024-08-05T11:12:29.536452Z","iopub.status.idle":"2024-08-05T11:12:29.542146Z","shell.execute_reply.started":"2024-08-05T11:12:29.536398Z","shell.execute_reply":"2024-08-05T11:12:29.540997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Following cell is used to visualize various performance metrics of a model by displaying plots that were generated during the evaluation process","metadata":{}},{"cell_type":"code","source":"display_curves(test_path) ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T11:12:29.543335Z","iopub.execute_input":"2024-08-05T11:12:29.543667Z","iopub.status.idle":"2024-08-05T11:12:35.309177Z","shell.execute_reply.started":"2024-08-05T11:12:29.543632Z","shell.execute_reply":"2024-08-05T11:12:35.308226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The block of code provided is used to visualize a random set of images from the test dataset along with the predictions made by the trained **YOLO** model.\n\nThis code snippet performs the following tasks:\n* **Initialize Plot**: Sets up a large figure for displaying images.\n* **Select Random Image**: Chooses a random image index from the test dataset.\n* **Display Actual Image**: Shows the actual image from the test dataset.\n* **Make Predictions**: Uses the YOLO model to predict objects in the image.\n* **Display Predictions**: Shows the image with bounding boxes and labels for the detected objects.","metadata":{}},{"cell_type":"code","source":"#Plot Initialization\nplt.figure(figsize=(60,60))\n\n#Random Image Selection\nm=random.randint(0, 150) \n\n#Plotting Loop\nfor i in range(1,8,2):\n    test_image=os.path.join(imgtestpath, os.listdir(imgtestpath)[m])\n    ax=plt.subplot(4,2,i)\n    \n    #Display actual image\n    plt.imshow(cv2.imread(test_image)) \n    plt.xticks([])\n    plt.yticks([])\n    plt.title(\"Actual image\", fontsize = 40)\n    \n    #Predict \n    res = model(test_image)\n    res_plotted = res[0].plot()\n    ax=plt.subplot(4,2,i+1)\n    \n    #Display image with predictions\n    plt.imshow(res_plotted)\n    plt.title(\"Image with predictions\", fontsize = 40)\n    plt.xticks([])\n    plt.yticks([])\n    m=m+1","metadata":{"execution":{"iopub.status.busy":"2024-08-05T11:12:35.310558Z","iopub.execute_input":"2024-08-05T11:12:35.310918Z","iopub.status.idle":"2024-08-05T11:12:42.452583Z","shell.execute_reply.started":"2024-08-05T11:12:35.310887Z","shell.execute_reply":"2024-08-05T11:12:42.450911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}